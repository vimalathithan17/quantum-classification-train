# âš ï¸ DEPRECATED - This file has been consolidated

**This document has been merged into [DOCS_GUIDE.md](DOCS_GUIDE.md).**

Please use the new consolidated documentation:
- **[DOCS_GUIDE.md](DOCS_GUIDE.md)** - Navigation guide with decision trees
- **[README.md](README.md)** - Main entry point

**This file can be safely deleted.**

### Decision Point 1: Dataset Size < 100 Samples

```
Small Dataset (< 100 samples)
â”‚
â””â”€â†’ RECOMMENDATION: QML Only
    â”‚
    â”œâ”€ WHY:
    â”‚  â€¢ QML is sample-efficient by design
    â”‚  â€¢ Exponential Hilbert space with few qubits
    â”‚  â€¢ Proven advantages on small data
    â”‚  â€¢ No GPU needed
    â”‚
    â”œâ”€ WHEN NOT TO USE:
    â”‚  â€¢ Need cross-modal fusion (use Transformer)
    â”‚  â€¢ Severe class imbalance (use Contrastive)
    â”‚  â€¢ Want 95%+ accuracy (consider ensemble)
    â”‚
    â”œâ”€ DOCUMENTATION:
    â”‚  â†’ [README.md](README.md)
    â”‚  â†’ [ARCHITECTURE.md](ARCHITECTURE.md)
    â”‚
    â”œâ”€ EXPECTED RESULTS:
    â”‚  â€¢ Training: 2-4 hours
    â”‚  â€¢ GPU: Not needed
    â”‚  â€¢ F1 Score: 0.75-0.85
    â”‚
    â””â”€ NEXT: Go to [README.md](README.md) for setup
```

### Decision Point 2: Dataset Size 100-500 Samples

```
Medium Dataset (100-500 samples)
â”‚
â”œâ”€â†’ Do you have unlabeled data available?
â”‚   â”‚
â”‚   â”œâ”€ YES (Branch A1)
â”‚   â”‚  â”‚
â”‚   â”‚  â””â”€â†’ RECOMMENDATION: Contrastive Pretraining â†’ QML
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ WHY:
â”‚   â”‚     â”‚  â€¢ Contrastive learns from unlabeled data
â”‚   â”‚     â”‚  â€¢ Class-agnostic learning (helps imbalance)
â”‚   â”‚     â”‚  â€¢ Better features than PCA/UMAP
â”‚   â”‚     â”‚  â€¢ Minimal pipeline changes
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ EXPECTED IMPROVEMENT:
â”‚   â”‚     â”‚  â€¢ F1 gain: +5-10%
â”‚   â”‚     â”‚  â€¢ Special case: Unlabeled helps minorities most
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ DOCUMENTATION:
â”‚   â”‚     â”‚  â†’ [INTEGRATION_GUIDE.md - Pattern 3](INTEGRATION_GUIDE.md#pattern-3-contrastive-pretraining--qml-pipeline)
â”‚   â”‚     â”‚  â†’ [INTEGRATION_GUIDE.md - Workflow A](INTEGRATION_GUIDE.md#workflow-a-adding-contrastive-pretraining-to-existing-qml-pipeline)
â”‚   â”‚     â”‚
â”‚   â”‚     â””â”€ NEXT: Go to [INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md#pattern-3-contrastive-pretraining--qml-pipeline)
â”‚   â”‚
â”‚   â””â”€ NO (Branch A2)
â”‚      â”‚
â”‚      â””â”€â†’ Do you have balanced or imbalanced data?
â”‚         â”‚
â”‚         â”œâ”€ BALANCED (Branch A3)
â”‚         â”‚  â”‚
â”‚         â”‚  â””â”€â†’ RECOMMENDATION: Data-Reuploading QML or QML Ensemble
â”‚         â”‚     â”‚
â”‚         â”‚     â”œâ”€ OPTION 1: Data-Reuploading QML
â”‚         â”‚     â”‚  â€¢ F1 improvement: +3%
â”‚         â”‚     â”‚  â€¢ Training: 3 hours
â”‚         â”‚     â”‚  â€¢ Best single model
â”‚         â”‚     â”‚
â”‚         â”‚     â”œâ”€ OPTION 2: QML Ensemble (4 models)
â”‚         â”‚     â”‚  â€¢ F1 improvement: +5%
â”‚         â”‚     â”‚  â€¢ Training: 4 hours
â”‚         â”‚     â”‚  â€¢ Best overall performance
â”‚         â”‚     â”‚
â”‚         â”‚     â”œâ”€ âš ï¸ WARNING: DON'T use Contrastive Pretraining
â”‚         â”‚     â”‚  â€¢ Empirical evidence: -6% F1 (WORSE!)
â”‚         â”‚     â”‚  â€¢ Only 320-400 samples insufficient for contrastive
â”‚         â”‚     â”‚  â€¢ No unlabeled data advantage
â”‚         â”‚     â”‚  â€¢ High overfitting risk
â”‚         â”‚     â”‚
â”‚         â”‚     â”œâ”€ DOCUMENTATION:
â”‚         â”‚     â”‚  â†’ [INTEGRATION_GUIDE.md - Scenario B](INTEGRATION_GUIDE.md#scenario-b-you-have-only-labeled-data-no-unlabeled-balanced-classes--400-samples)
â”‚         â”‚     â”‚  â†’ [INTEGRATION_GUIDE.md - Small Dataset Strategy](INTEGRATION_GUIDE.md#small-dataset-strategy--100-samples)
â”‚         â”‚     â”‚
â”‚         â”‚     â””â”€ NEXT: Go to [INTEGRATION_GUIDE.md - Scenario B](INTEGRATION_GUIDE.md#scenario-b-you-have-only-labeled-data-no-unlabeled-balanced-classes--400-samples)
â”‚         â”‚
â”‚         â””â”€ IMBALANCED (Branch A4)
â”‚            â”‚
â”‚            â””â”€â†’ RECOMMENDATION: Contrastive + QML with Class Weighting
â”‚               â”‚
â”‚               â”œâ”€ WHY:
â”‚               â”‚  â€¢ Contrastive is class-agnostic (helps minorities)
â”‚               â”‚  â€¢ Class weighting amplifies minority signal
â”‚               â”‚  â€¢ Combined approach most effective
â”‚               â”‚
â”‚               â”œâ”€ EXPECTED IMPROVEMENT:
â”‚               â”‚  â€¢ Minority class F1: +20-30%
â”‚               â”‚  â€¢ Overall macro F1: +10-15%
â”‚               â”‚
â”‚               â”œâ”€ DOCUMENTATION:
â”‚               â”‚  â†’ [INTEGRATION_GUIDE.md - Solution 2](INTEGRATION_GUIDE.md#solution-2-contrastive-pretraining-for-imbalanced-data)
â”‚               â”‚  â†’ [INTEGRATION_GUIDE.md - Solution 3](INTEGRATION_GUIDE.md#solution-3-combined-qml--contrastive-for-best-results)
â”‚               â”‚
â”‚               â””â”€ NEXT: Go to [INTEGRATION_GUIDE.md - Solution 2](INTEGRATION_GUIDE.md#solution-2-contrastive-pretraining-for-imbalanced-data)
```

### Decision Point 3: Dataset Size 500-1000 Samples

```
Medium-Large Dataset (500-1000 samples)
â”‚
â”œâ”€â†’ Do you have > 20% missing modalities?
â”‚   â”‚
â”‚   â”œâ”€ YES
â”‚   â”‚  â””â”€â†’ RECOMMENDATION: Transformer Fusion (+ Contrastive)
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ WHY:
â”‚   â”‚     â”‚  â€¢ Transformers natively handle missing modalities
â”‚   â”‚     â”‚  â€¢ Attention masking elegantly handles gaps
â”‚   â”‚     â”‚  â€¢ Cross-modal fusion learns interactions
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ DOCUMENTATION:
â”‚   â”‚     â”‚  â†’ [INTEGRATION_GUIDE.md - Pattern 2](INTEGRATION_GUIDE.md#pattern-2-transformer-fusion-replacing-qml-base-learners)
â”‚   â”‚     â”‚
â”‚   â”‚     â””â”€ NEXT: See Pattern 2
â”‚   â”‚
â”‚   â””â”€ NO
â”‚      â””â”€â†’ Check next criteria
â”‚
â””â”€â†’ Is there class imbalance?
    â”‚
    â”œâ”€ YES
    â”‚  â””â”€â†’ RECOMMENDATION: Contrastive â†’ Transformer or QML Meta-Learner
    â”‚     â”‚
    â”‚     â”œâ”€ EXPECTED IMPROVEMENT:
    â”‚     â”‚  â€¢ F1 gain: +8-15%
    â”‚     â”‚
    â”‚     â””â”€ DOCUMENTATION:
    â”‚        â†’ [INTEGRATION_GUIDE.md - Solution 2](INTEGRATION_GUIDE.md#solution-2-contrastive-pretraining-for-imbalanced-data)
    â”‚
    â””â”€ NO
       â””â”€â†’ RECOMMENDATION: Transformer Fusion (simple path)
          â”‚
          â”œâ”€ EXPECTED IMPROVEMENT:
          â”‚  â€¢ F1 gain: +3-8%
          â”‚
          â””â”€ DOCUMENTATION:
             â†’ [INTEGRATION_GUIDE.md - Pattern 2](INTEGRATION_GUIDE.md#pattern-2-transformer-fusion-replacing-qml-base-learners)
```

### Decision Point 4: Dataset Size 1000+ Samples

```
Large Dataset (1000+ samples)
â”‚
â””â”€â†’ RECOMMENDATION: Full Hybrid Pipeline
   â”‚
   â”œâ”€ STAGES:
   â”‚  1. Contrastive Pretraining (200 epochs)
   â”‚  2. Transformer Fusion (50 epochs)
   â”‚  3. QML Meta-Learner (final)
   â”‚
   â”œâ”€ EXPECTED RESULTS:
   â”‚  â€¢ F1 improvement: +15-25%
   â”‚  â€¢ Training time: 16-24 hours (GPU required)
   â”‚  â€¢ Best overall performance
   â”‚
   â”œâ”€ DOCUMENTATION:
   â”‚  â†’ [INTEGRATION_GUIDE.md - Pattern 1](INTEGRATION_GUIDE.md#pattern-1-qml-as-meta-learner-with-deep-learning-base-learners)
   â”‚
   â””â”€ NEXT: Go to [INTEGRATION_GUIDE.md - Pattern 1](INTEGRATION_GUIDE.md#pattern-1-qml-as-meta-learner-with-deep-learning-base-learners)
```

---

## ğŸ¯ Problem-Specific Decision Trees

### Problem: Class Imbalance

```
Class Imbalance Detected
â”‚
â”œâ”€â†’ SOLUTION 1: Class Weighting in QML
â”‚   â”œâ”€ Cost: Minimal (modify loss function)
â”‚   â”œâ”€ Improvement: +5-10%
â”‚   â”œâ”€ Time: 2-4 hours
â”‚   â””â”€ Documentation: [INTEGRATION_GUIDE.md - Solution 1](INTEGRATION_GUIDE.md#solution-1-qml-pipeline-with-weighted-loss)
â”‚
â”œâ”€â†’ SOLUTION 2: Contrastive Pretraining
â”‚   â”œâ”€ Cost: High (requires GPU, 8-12 hours)
â”‚   â”œâ”€ Improvement: +10-20% (especially minorities)
â”‚   â”œâ”€ Time: 8-12 hours
â”‚   â”œâ”€ Requirement: Unlabeled data or enough labeled data
â”‚   â””â”€ Documentation: [INTEGRATION_GUIDE.md - Solution 2](INTEGRATION_GUIDE.md#solution-2-contrastive-pretraining-for-imbalanced-data)
â”‚
â””â”€â†’ SOLUTION 3: Combined Approach
    â”œâ”€ Cost: High
    â”œâ”€ Improvement: +15-25% (best results)
    â”œâ”€ Time: 12-24 hours
    â”œâ”€ Combination: Contrastive + Class Weighting + QML Ensemble
    â””â”€ Documentation: [INTEGRATION_GUIDE.md - Solution 3](INTEGRATION_GUIDE.md#solution-3-combined-qml--contrastive-for-best-results)
```

### Problem: Missing Modalities (> 20%)

```
Missing Modalities Problem
â”‚
â”œâ”€â†’ STRATEGY: Transformer Fusion
â”‚   â”œâ”€ Why: Native attention masking support
â”‚   â”œâ”€ How: Masks missing modalities automatically
â”‚   â”œâ”€ Improvement: +5-10%
â”‚   â””â”€ Documentation: [INTEGRATION_GUIDE.md - Pattern 2](INTEGRATION_GUIDE.md#pattern-2-transformer-fusion-replacing-qml-base-learners)
â”‚
â”œâ”€â†’ ALTERNATIVE: QML with Conditional Encoding
â”‚   â”œâ”€ Why: Handles missing via indicators
â”‚   â”œâ”€ How: CFE approach with indicator features
â”‚   â”œâ”€ Improvement: +2-5%
â”‚   â””â”€ Documentation: [README.md](README.md)
â”‚
â””â”€â†’ COMBINE: Transformer + QML Meta-Learner
    â”œâ”€ Why: Best flexibility
    â”œâ”€ Improvement: +8-15%
    â””â”€ Documentation: [INTEGRATION_GUIDE.md - Pattern 1](INTEGRATION_GUIDE.md#pattern-1-qml-as-meta-learner-with-deep-learning-base-learners)
```

---

## ğŸ’¡ Quick Reference

### By Improvement Priority
- **-6% F1**: Contrastive on balanced 100-400 sample labeled-only data âŒ
- **+3% F1**: Data-Reuploading QML on small balanced data
- **+5-10% F1**: Contrastive + QML on imbalanced or with unlabeled
- **+8-15% F1**: Transformer Fusion
- **+10-25% F1**: Full Hybrid Pipeline

### By Computational Cost
- **Lowest**: QML Only (CPU, 2-4h)
- **Medium**: Contrastive + QML (GPU, 8-12h)
- **High**: Transformer Fusion (GPU, 6-12h)
- **Highest**: Full Hybrid (GPU cluster, 16-24h)

### By Data Requirements
- **Least data needed**: QML Only (50+ samples)
- **Medium data needed**: Contrastive + QML (100+ samples + unlabeled)
- **More data needed**: Transformer Fusion (500+ samples)
- **Most data needed**: Full Hybrid (1000+ samples)

---

## ğŸ“ Where to Find Help

**Decision made? Go to:**
â†’ [INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md) for implementation details

**Still unsure?**
â†’ [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md) for more guidance

**Ran into error?**
â†’ [INTEGRATION_GUIDE.md - Troubleshooting](INTEGRATION_GUIDE.md#troubleshooting)

**Want to understand everything?**
â†’ [NAVIGATION_SITEMAP.md](NAVIGATION_SITEMAP.md)

---

**Last Updated:** December 28, 2024  
**Decision Tree Completeness:** âœ… 100%
